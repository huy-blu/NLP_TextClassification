{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PhanLoaiChuDe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3ZNcXC2xR3y",
        "outputId": "dd64e3d2-a284-4504-cd78-0ee5899f839a"
      },
      "source": [
        "!apt-get install python3.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.7-minimal libpython3.7-stdlib python3.7-minimal\n",
            "Suggested packages:\n",
            "  python3.7-venv python3.7-doc binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.7-minimal libpython3.7-stdlib python3.7 python3.7-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 4,282 kB of archives.\n",
            "After this operation, 22.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libpython3.7-minimal amd64 3.7.5-2~18.04 [546 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3.7-minimal amd64 3.7.5-2~18.04 [1,691 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libpython3.7-stdlib amd64 3.7.5-2~18.04 [1,745 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3.7 amd64 3.7.5-2~18.04 [301 kB]\n",
            "Fetched 4,282 kB in 1s (4,002 kB/s)\n",
            "Selecting previously unselected package libpython3.7-minimal:amd64.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.7-minimal_3.7.5-2~18.04_amd64.deb ...\n",
            "Unpacking libpython3.7-minimal:amd64 (3.7.5-2~18.04) ...\n",
            "Selecting previously unselected package python3.7-minimal.\n",
            "Preparing to unpack .../python3.7-minimal_3.7.5-2~18.04_amd64.deb ...\n",
            "Unpacking python3.7-minimal (3.7.5-2~18.04) ...\n",
            "Selecting previously unselected package libpython3.7-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.7-stdlib_3.7.5-2~18.04_amd64.deb ...\n",
            "Unpacking libpython3.7-stdlib:amd64 (3.7.5-2~18.04) ...\n",
            "Selecting previously unselected package python3.7.\n",
            "Preparing to unpack .../python3.7_3.7.5-2~18.04_amd64.deb ...\n",
            "Unpacking python3.7 (3.7.5-2~18.04) ...\n",
            "Setting up libpython3.7-minimal:amd64 (3.7.5-2~18.04) ...\n",
            "Setting up python3.7-minimal (3.7.5-2~18.04) ...\n",
            "Setting up libpython3.7-stdlib:amd64 (3.7.5-2~18.04) ...\n",
            "Setting up python3.7 (3.7.5-2~18.04) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVXVjMVgxYVA",
        "outputId": "c955b6fb-38be-4b44-f3a2-40cfc87f69c2"
      },
      "source": [
        "!python3.7 setup.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3.7: can't open file 'setup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIDrylcBxd60",
        "outputId": "353d36ed-3608-462f-f0ad-e8e1cba810f5"
      },
      "source": [
        "pip install underthesea"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting underthesea\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/53/50ab756869f23d2bd1b3978d6b1c17c650d90abd5928701e7bd65adb6986/underthesea-1.3.0-py3-none-any.whl (7.5MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from underthesea) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from underthesea) (2.23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from underthesea) (3.13)\n",
            "Collecting scikit-learn<0.22,>=0.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from underthesea) (3.2.5)\n",
            "Collecting python-crfsuite>=0.9.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 40.6MB/s \n",
            "\u001b[?25hCollecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from underthesea) (4.41.1)\n",
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from underthesea) (0.17.0)\n",
            "Collecting torch<=1.5.1,>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/01/457b49d790b6c4b9720e6f9dbbb617692f6ce8afdaadf425c055c41a7416/torch-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (753.2MB)\n",
            "\u001b[K     |████████████████████████████████| 753.2MB 22kB/s \n",
            "\u001b[?25hCollecting transformers<=3.5.1,>=3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.22,>=0.20->underthesea) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.22,>=0.20->underthesea) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->underthesea) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<=1.5.1,>=1.1.0->underthesea) (0.16.0)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 42.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (20.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.12.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.8)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<=3.5.1,>=3.5.0->underthesea) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<=3.5.1,>=3.5.0->underthesea) (50.3.2)\n",
            "Building wheels for collected packages: seqeval, sacremoses\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=61294354b7f975b0e8da274d3065ff26fc00859cd196faa9ee2324f36f483009\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=966bd8177aab23a3c52361beefd9d2dc4145f12c90888326b1f9b6c47b37adb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built seqeval sacremoses\n",
            "\u001b[31mERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 1.5.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scikit-learn, python-crfsuite, unidecode, seqeval, torch, sentencepiece, sacremoses, tokenizers, transformers, underthesea\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "Successfully installed python-crfsuite-0.9.7 sacremoses-0.0.43 scikit-learn-0.21.3 sentencepiece-0.1.91 seqeval-1.2.2 tokenizers-0.9.3 torch-1.5.1 transformers-3.5.1 underthesea-1.3.0 unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opZ_sUsVxd92"
      },
      "source": [
        "from underthesea import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd5g2SSfyc3c"
      },
      "source": [
        "# Cài đặt một số hàm tiền xử lý văn bản cần thiết\r\n",
        "# !pip3 install --user underthesea\r\n",
        "import regex as re\r\n",
        "from underthesea import word_tokenize\r\n",
        " \r\n",
        "uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\r\n",
        "unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\r\n",
        " \r\n",
        "def loaddicchar():\r\n",
        "    dic = {}\r\n",
        "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\r\n",
        "        '|')\r\n",
        "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\r\n",
        "        '|')\r\n",
        "    for i in range(len(char1252)):\r\n",
        "        dic[char1252[i]] = charutf8[i]\r\n",
        "    return dic\r\n",
        "dicchar = loaddicchar()\r\n",
        "\r\n",
        "# Hàm chuyển Unicode dựng sẵn về Unicde tổ hợp (phổ biến hơn)\r\n",
        "def convert_unicode(txt):\r\n",
        "    return re.sub(\r\n",
        "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\r\n",
        "        lambda x: dicchar[x.group()], txt)\r\n",
        "\r\n",
        "bang_nguyen_am = [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\r\n",
        "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\r\n",
        "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\r\n",
        "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\r\n",
        "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\r\n",
        "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\r\n",
        "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\r\n",
        "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\r\n",
        "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\r\n",
        "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\r\n",
        "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\r\n",
        "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\r\n",
        "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\r\n",
        "\r\n",
        "nguyen_am_to_ids = {}\r\n",
        "\r\n",
        "for i in range(len(bang_nguyen_am)):\r\n",
        "    for j in range(len(bang_nguyen_am[i]) - 1):\r\n",
        "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\r\n",
        "\r\n",
        "def chuan_hoa_dau_tu_tieng_viet(word):\r\n",
        "    if not is_valid_vietnam_word(word):\r\n",
        "        return word\r\n",
        "\r\n",
        "    chars = list(word)\r\n",
        "    dau_cau = 0\r\n",
        "    nguyen_am_index = []\r\n",
        "    qu_or_gi = False\r\n",
        "    for index, char in enumerate(chars):\r\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\r\n",
        "        if x == -1:\r\n",
        "            continue\r\n",
        "        elif x == 9:  # check qu\r\n",
        "            if index != 0 and chars[index - 1] == 'q':\r\n",
        "                chars[index] = 'u'\r\n",
        "                qu_or_gi = True\r\n",
        "        elif x == 5:  # check gi\r\n",
        "            if index != 0 and chars[index - 1] == 'g':\r\n",
        "                chars[index] = 'i'\r\n",
        "                qu_or_gi = True\r\n",
        "        if y != 0:\r\n",
        "            dau_cau = y\r\n",
        "            chars[index] = bang_nguyen_am[x][0]\r\n",
        "        if not qu_or_gi or index != 1:\r\n",
        "            nguyen_am_index.append(index)\r\n",
        "    if len(nguyen_am_index) < 2:\r\n",
        "        if qu_or_gi:\r\n",
        "            if len(chars) == 2:\r\n",
        "                x, y = nguyen_am_to_ids.get(chars[1])\r\n",
        "                chars[1] = bang_nguyen_am[x][dau_cau]\r\n",
        "            else:\r\n",
        "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\r\n",
        "                if x != -1:\r\n",
        "                    chars[2] = bang_nguyen_am[x][dau_cau]\r\n",
        "                else:\r\n",
        "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\r\n",
        "            return ''.join(chars)\r\n",
        "        return word\r\n",
        "\r\n",
        "    for index in nguyen_am_index:\r\n",
        "        x, y = nguyen_am_to_ids[chars[index]]\r\n",
        "        if x == 4 or x == 8:  # ê, ơ\r\n",
        "            chars[index] = bang_nguyen_am[x][dau_cau]\r\n",
        "            # for index2 in nguyen_am_index:\r\n",
        "            #     if index2 != index:\r\n",
        "            #         x, y = nguyen_am_to_ids[chars[index]]\r\n",
        "            #         chars[index2] = bang_nguyen_am[x][0]\r\n",
        "            return ''.join(chars)\r\n",
        "\r\n",
        "    if len(nguyen_am_index) == 2:\r\n",
        "        if nguyen_am_index[-1] == len(chars) - 1:\r\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\r\n",
        "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\r\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\r\n",
        "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\r\n",
        "        else:\r\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\r\n",
        "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\r\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\r\n",
        "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\r\n",
        "    else:\r\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\r\n",
        "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\r\n",
        "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\r\n",
        "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\r\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\r\n",
        "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\r\n",
        "    return ''.join(chars)\r\n",
        "\r\n",
        "\r\n",
        "def is_valid_vietnam_word(word):\r\n",
        "    chars = list(word)\r\n",
        "    nguyen_am_index = -1\r\n",
        "    for index, char in enumerate(chars):\r\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\r\n",
        "        if x != -1:\r\n",
        "            if nguyen_am_index == -1:\r\n",
        "                nguyen_am_index = index\r\n",
        "            else:\r\n",
        "                if index - nguyen_am_index != 1:\r\n",
        "                    return False\r\n",
        "                nguyen_am_index = index\r\n",
        "    return True\r\n",
        "\r\n",
        "\r\n",
        "def chuan_hoa_dau_cau_tieng_viet(sentence):\r\n",
        "    \"\"\"\r\n",
        "        Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\r\n",
        "        :param sentence:\r\n",
        "        :return:\r\n",
        "        \"\"\"\r\n",
        "    sentence = sentence.lower()\r\n",
        "    words = sentence.split()\r\n",
        "    for index, word in enumerate(words):\r\n",
        "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\r\n",
        "        # print(cw)\r\n",
        "        if len(cw) == 3:\r\n",
        "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\r\n",
        "        words[index] = ''.join(cw)\r\n",
        "    return ' '.join(words)\r\n",
        "\r\n",
        "def remove_html(txt):\r\n",
        "    return re.sub(r'<[^>]*>', '', txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGQwYfaqyc6U",
        "outputId": "94e8a3cf-0563-48ed-d129-02a44d0ba368"
      },
      "source": [
        "def text_preprocess(document):\r\n",
        "    # xóa html code\r\n",
        "    document = remove_html(document)\r\n",
        "    # chuẩn hóa unicode\r\n",
        "    document = convert_unicode(document)\r\n",
        "    # chuẩn hóa cách gõ dấu tiếng Việt\r\n",
        "    document = chuan_hoa_dau_cau_tieng_viet(document)\r\n",
        "    # tách từ\r\n",
        "    document = word_tokenize(document, format=\"text\")\r\n",
        "    # đưa về lower\r\n",
        "    document = document.lower()\r\n",
        "    # xóa các ký tự không cần thiết\r\n",
        "    document = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',document)\r\n",
        "    # xóa khoảng trắng thừa\r\n",
        "    document = re.sub(r'\\s+', ' ', document).strip()\r\n",
        "    return document\r\n",
        "\r\n",
        "document = \"\"\"\r\n",
        "TP HCM phạt người không đeo khẩu trang nơi công cộng\r\n",
        "Người dân ở thành phố không đeo khẩu trang nơi công cộng sẽ bị xử phạt mức cao nhất 300.000 đồng, từ ngày 5/8.\r\n",
        "\r\n",
        "Yêu cầu này được Chủ tịch UBND thành phố Nguyễn Thành Phong đưa ra tại cuộc họp Ban chỉ đạo phòng chống dịch bệnh Covid-19 của TP HCM chiều 3/8.\r\n",
        "\r\n",
        "Việc xử phạt không đeo khẩu trang nơi công cộng được TP HCM cũng như các địa phương khác thực hiện từ cuối tháng 3 khi Covid-19 bùng phát. Tuy nhiên, sau khi hết thực hiện cách ly xã hội từ ngày 23/4, việc đeo khẩu trang nơi công cộng chỉ dừng lại ở mức khuyến cáo.\r\n",
        "\r\n",
        "Theo Nghị định số 176/2013, người dân không đeo khẩu trang nơi công cộng sẽ bị xử phạt từ 100.000 đến 300.000 đồng. Trong khoảng một tháng áp dụng trước đó, TP HCM đã xử phạt hơn 4.300 trường hợp với gần 870 triệu đồng.\r\n",
        "\r\n",
        "Theo ông Phong, việc đeo khẩu trang đã được khẳng định có thể tránh lây lan dịch bệnh cho người khác và bảo vệ sức khỏe cho người sử dụng. \"Sở Công thương phải nắm nguồn cung ứng khẩu trang, chủ động thông báo các điểm bán để người dân dễ dàng mua vì đã xử phạt thì phải bảo đảm đủ nguồn cung\", ông Phong nói.\r\n",
        "\r\n",
        "Đội trật tự đô thị phường Bến Nghé, quận 1, xử phạt người không đeo khẩu trang trên phố đi bộ Nguyễn Huệ, chiều 15/4. Ảnh: Quỳnh Trần.\r\n",
        "Đội trật tự đô thị phường Bến Nghé, quận 1, xử phạt người không đeo khẩu trang trên phố đi bộ Nguyễn Huệ, chiều 15/4. Ảnh: Quỳnh Trần.\r\n",
        "\r\n",
        "Bí thư Thành uỷ Nguyễn Thiện Nhân cũng cho rằng việc đeo khẩu trang là một trong những biện pháp cơ bản để tránh dịch bệnh lây lan. Việc này rất dễ làm, không tốn nhiều tiền nhưng nhiều nước bỏ lơi và đã bị \"vỡ trận\".\r\n",
        "\r\n",
        "\"Ngoài đường hiện có ít nhất 20% người không đeo khẩu trang. Người không đeo không những tự rước bệnh vào mình mà còn nguy cơ lây cho người khác. Đeo khẩu trang hơi cực tí thôi nhưng đi đâu cũng nên đeo để giữ an toàn\", ông Nhân nói và khẳng định thành phố bảo đảm không thiếu khẩu trang cho người dân.\r\n",
        "\r\n",
        "Chủ tịch UBND thành phố Nguyễn Thành Phong cũng cho biết đã đồng ý việc tái lập các chốt kiểm soát ở cửa ngõ TP HCM để phòng chống Covid-19.\r\n",
        "\r\n",
        "Trước đó, thành phố đã lập 62 chốt kiểm soát, hoạt động 24/24 từ ngày 4/4 để phòng chống dịch. Lực lượng tham gia là Công an thành phố, Sở Y tế, Bộ Tư lệnh thành phố, Thanh tra giao thông, Ban Quản lý An toàn thực phẩm, quản lý thị trường.\r\n",
        "\r\n",
        "Trong đó, 16 chốt chính (cấp thành phố) đặt tại: Trạm thu phí Long Phước (cao tốc TP HCM - Long Thành - Dầu Giây), cao tốc Trung Lương, cầu Đôi (đường Trần Văn Giàu), đường Ba Làng, đường Xuyên Á (quốc lộ 22), cầu Phú Cường, cầu Vĩnh Bình, cầu vượt Sóng Thần, quốc lộ 1K, quốc lộ 50, quốc lộ 1A, cầu Đồng Nai, Bến xe Miền Tây, Bến xe miền Đông, sân bay Tân Sơn Nhất, cảng Cát Lái.\r\n",
        "\r\n",
        "Đến ngày 23/4, chính quyền thành phố dừng hoạt động các chốt này vì dịch bệnh đã được khống chế, TP HCM dừng cách ly xã hội theo Chỉ thị 19 của Thủ tướng.\r\n",
        "\r\n",
        "Sau 19 ngày hoạt động, các chốt chính đã kiểm tra gần 270.000 xe, trong đó có 235.000 ôtô; gần 600.000 người được kiểm tra y tế, đo thân nhiệt, bao gồm cả 3.000 người nước ngoài; hơn 130.000 người được yêu cầu khai báo y tế.\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "document = text_preprocess(document)\r\n",
        "print(document)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tp hcm phạt người không đeo khẩu_trang nơi công_cộng người dân ở thành_phố không đeo khẩu_trang nơi công_cộng sẽ bị xử_phạt mức cao nhất 300 000 đồng từ ngày 58 yêu_cầu này được chủ_tịch ubnd thành_phố nguyễn_thành phong đưa ra tại cuộc họp ban chỉ_đạo phòng_chống dịch_bệnh covid 19 của tp hcm chiều 38 việc xử_phạt không đeo khẩu_trang nơi công_cộng được tp hcm cũng như các địa_phương khác thực_hiện từ cuối tháng 3 khi covid 19 bùng_phát tuy_nhiên sau khi hết thực_hiện cách_ly xã_hội từ ngày 234 việc đeo khẩu_trang nơi công_cộng chỉ dừng lại ở mức khuyến_cáo theo nghị_định số 1762013 người_dân không đeo khẩu_trang nơi công_cộng sẽ bị xử_phạt từ 100 000 đến 300 000 đồng trong khoảng một tháng áp_dụng trước đó tp hcm đã xử_phạt hơn 4 300 trường_hợp với gần 870 triệu đồng theo ông phong việc đeo khẩu_trang đã được khẳng_định có_thể tránh lây_lan dịch_bệnh cho người khác và bảo_vệ sức_khỏe cho người sử_dụng sở công_thương phải nắm nguồn cung_ứng_khẩu_trang chủ_động thông_báo các điểm bán để người dân dễ_dàng mua vì đã xử_phạt thì phải bảo_đảm đủ nguồn cung ông phong nói đội trật_tự đô_thị phường bến_nghé quận 1 xử_phạt người không đeo khẩu_trang trên phố đi bộ nguyễn_huệ chiều 154 ảnh quỳnh trần đội trật_tự đô_thị phường bến_nghé quận 1 xử_phạt người không đeo khẩu_trang trên phố đi bộ nguyễn_huệ chiều 154 ảnh quỳnh trần bí_thư thành_ủy nguyễn_thiện_nhân cũng cho rằng việc đeo khẩu_trang là một trong những biện_pháp cơ_bản để tránh dịch_bệnh lây_lan việc này rất dễ làm không tốn nhiều tiền nhưng nhiều nước bỏ_lơi và đã bị vỡ trận ngoài đường hiện có ít_nhất 20 người không đeo khẩu_trang người không đeo không_những tự rước bệnh vào mình mà_còn nguy_cơ lây cho người khác đeo khẩu_trang hơi cực tí thôi nhưng đi đâu cũng nên đeo để giữ an_toàn ông nhân nói và khẳng_định thành_phố bảo_đảm không thiếu khẩu_trang cho người dân chủ_tịch ubnd thành_phố nguyễn_thành phong cũng cho biết đã đồng_ý việc tái_lập các chốt kiểm_soát ở cửa_ngõ tp hcm để phòng_chống covid 19 trước đó thành_phố đã lập 62 chốt kiểm_soát hoạt_động 2424 từ ngày 44 để phòng_chống dịch lực_lượng tham_gia là công_an thành_phố sở y_tế bộ_tư_lệnh thành_phố thanh_tra giao_thông ban quản_lý an_toàn thực_phẩm quản_lý thị_trường trong đó 16 chốt chính cấp thành_phố đặt tại trạm thu phí long phước cao_tốc tp hcm long thành dầu giây cao_tốc trung_lương cầu đôi đường trần_văn_giàu đường ba làng đường xuyên á quốc_lộ 22 cầu phú_cường cầu vĩnh_bình cầu_vượt sóng_thần quốc_lộ 1 k quốc_lộ 50 quốc_lộ 1 a cầu đồng nai bến_xe miền tây bến_xe miền đông sân_bay tân_sơn nhất cảng cát_lái đến ngày 234 chính_quyền thành_phố dừng hoạt_động các chốt này vì dịch_bệnh đã được khống_chế tp hcm dừng cách_ly xã_hội theo chỉ_thị 19 của thủ_tướng sau 19 ngày hoạt_động các chốt chính đã kiểm_tra gần 270 000 xe trong đó có 235 000 ôtô gần 600 000 người được kiểm_tra y_tế đo thân_nhiệt bao_gồm cả 3 000 người nước_ngoài hơn 130 000 người được yêu_cầu khai_báo y_tế\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OY9e8CPyc9N",
        "outputId": "8bcad925-94df-4105-8f9e-feab8d234e78"
      },
      "source": [
        "# Download data\r\n",
        "# Dữ liệu đã tiền xử lý có dạng: mỗi bài báo là một dòng, từ đầu tiên là nhãn (chủ đề) của dòng đó\r\n",
        "!wget -nc \"https://github.com/nguyenvanhieuvn/text-classification-tutorial/raw/master/news_categories.zip\"\r\n",
        "!unzip -n \"news_categories.zip\"\r\n",
        "!head \"news_categories.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-17 08:53:39--  https://github.com/nguyenvanhieuvn/text-classification-tutorial/raw/master/news_categories.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nguyenvanhieuvn/text-classification-tutorial/master/news_categories.zip [following]\n",
            "--2020-12-17 08:53:40--  https://raw.githubusercontent.com/nguyenvanhieuvn/text-classification-tutorial/master/news_categories.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 59696423 (57M) [application/zip]\n",
            "Saving to: ‘news_categories.zip’\n",
            "\n",
            "news_categories.zip 100%[===================>]  56.93M  82.3MB/s    in 0.7s    \n",
            "\n",
            "2020-12-17 08:53:41 (82.3 MB/s) - ‘news_categories.zip’ saved [59696423/59696423]\n",
            "\n",
            "Archive:  news_categories.zip\n",
            "  inflating: news_categories.txt     \n",
            "__label__thể_thao sanchez không dự trận khai màn nh anh cùng arsenal bóng_đá anh zing vn tuyển_thủ chile không kịp hồi_phục thể_lực để cùng pháo thủ_thành london tham_dự trận đầu_tiên tại premier_league 2015 2016 diễn ra ngày 9 8 arsenal tới singapore liverpool đổ_bộ xuống thái_lan hai đội_bóng danh_tiếng tại giải ngoại_hạng_anh bắt_đầu có chuyến du_đấu châu á thầy_trò hlv brendan_rodgers có_mặt tại thái_lan chuẩn_bị cho trận_đấu diễn ra ngày 14 7 trả_lời phỏng_vấn trong chuyến du_đấu tại singapore hlv arsene_wenger xác_nhận tiền_đạo alexis_sanchez sẽ vắng_mặt trong trận khai màn premier_league theo chiến_lược gia người pháp cựu ngôi_sao barca cần được nghỉ_ngơi sau khi tham_dự copa_america trên quê_hương alexis sẽ trở_lại arsenal ngày 3 8 các cầu_thủ thường lấy lại thể_lực trong khoảng 3 tuần mới có_thể thi_đấu alexis có_thể nghỉ ít hơn tuy_nhiên anh ấy chắc_chắn không tham_dự trận_đấu đầu_tiên của mùa_giải mới trang bbc dẫn lại bài phỏng_vấn của hlv wenger ngoài trận xông đất premier_league sanchez cũng không góp_mặt trong trận tranh community_shield với chelsea bởi trận_đấu này diễn ra ngày 2 8 một ngày trước khi chân_sút 26 tuổi trở_lại arsenal sanchez là nhân_tố then_chốt giúp chile lần đầu vô_địch copa_america ảnh bbc mùa_giải vừa_qua cựu tiền_đạo barcelona thi_đấu rất thuyết_phục anh ghi 25 bàn sau 52 trận giúp pháo_thủ vô_địch fa_cup và cán đích vị_trí thứ 3 tại premier_league theo đó arsenal giành vé dự vòng bảng champions_league mùa tới tại copa_america vừa_qua sanchez chỉ ghi 1 bàn tuy_nhiên giới chuyên_môn đánh_giá anh là một trong những mắt_xích quan_trọng nhất giúp chủ_nhà chile tiến tới chung_kết ở trận_đấu cuối_cùng sanchez và đồng_đội xuất_sắc đánh_bại argentina để lần đầu vô_địch giải_đấu danh_giá nhất nam_mỹ theo lịch arsenal sẽ nổ tiếng súng lệnh tại premier_league mùa này khi tiếp west_ham trên sân_nhà lúc 19h30 ngày 9 8 giống alexis_sanchez bộ đôi hậu_vệ pablo_zabaleta và martin_demichelis cũng không kịp cùng manchester_city đá trận khai_mạc premier_league manchester_united không nhận được sự phục_vụ của angel_di_maria và marcos_rojo bốn cầu_thủ này đều đá trọn trận chung_kết copa_america cùng đội_tuyển argentina arsenal f c câu_lạc_bộ bóng_đá arsenal còn được biết đến với biệt_danh pháo_thủ là một câu_lạc_bộ bóng_đá lớn tại anh có trụ_sở ở holloway london câu_lạc_bộ hiện đang chơi ở giải bóng_đá ngoại_hạng_anh là một trong những câu_lạc_bộ thành_công nhất của bóng_đá anh arsenal đã giành được tổng_cộng 13 danh_hiệu vô_địch quốc_gia năm 1913 đội_bóng chuyển về phía bắc lấy sân_vận_động highbury làm sân_nhà và thi_đấu tại đó trong suốt 93 năm năm 2006 đội_bóng chuyển đến sân_vận_động emirates và lấy đó làm sân_nhà cho đến nay arsenal là câu_lạc_bộ kình_địch với đội_bóng cùng khu_vực tottenham_hotspur bạn có biết thierry_henry là cầu_thủ ghi_bàn nhiều nhất cho câu_lạc_bộ với 228 bàn_thắng trong những năm 1999 đến 2007 và đầu năm 2012 thành_lập 1886 biệt_danh pháo_thủ sân_vận_động emirates \n",
            "__label__âm_nhạc những sao việt hóa_thân thành phó nháy trong mv nhạc_việt zing vn miu_lê tiêu_châu_như_quỳnh phùng_ngọc_huy đều chọn hình_tượng nhiếp_ảnh_gia khi xuất_hiện trong sản_phẩm riêng những sao việt hóa_thân thành phó nháy trong mv miu_lê tiêu_châu_như_quỳnh phùng_ngọc_huy đều chọn hình_tượng nhiếp_ảnh_gia khi xuất_hiện trong sản_phẩm riêng miu lê trong lặng thầm yêu lặng_thầm yêu là một trong những mv đánh_dấu sự trưởng_thành của miu_lê trong năm 2012 trong sản_phẩm này cô hóa_thân thành một nàng nhiếp_ảnh_gia xinh_đẹp và cá_tính công_việc dường_như chỉ dành cho phái_mạnh này đã khiến cô có cơ_duyên gặp_gỡ tình_yêu của mình hot boy tuấn_kiệt sau những lần chụp ảnh cho anh cô đã đem_lòng yêu chàng hot boy với nụ_cười tỏa nắng này tuy_nhiên khoảng_cách giữa hai người quá lớn miu lê chỉ là một cô_gái làm nghề nhiếp_ảnh cá_tính còn tuấn_kiệt lại là một hot boy điển_trai với tương_lai rộng_mở điều quan_trọng nhất là trước khi biết cô nhiếp_ảnh chàng_trai đã tìm được một_nửa của mình chấp_nhận là người đến sau miu lê chôn giấu tình_yêu sâu trong lòng và cầu_chúc cho tình_yêu của người_thương mỗi lúc nhớ tuấn_kiệt miu_lê thường ngắm lại những bức hình đã chụp về anh tất_cả những tấm ảnh đó chỉ làm cô thêm đau_lòng và cào xé tâm_can cuối_cùng cô quyết_định đi xa để tìm sự bình_yên trong tâm_hồn will 365 trong nơi anh không thuộc về nơi anh không thuộc về là một trong những mv khá đặc_biệt của 365 vì đây là lần đầu_tiên ngô_thanh_vân cho_phép các học_trò tình_tứ với gái lạ với mô típ mới 5 chàng_trai của 365 hóa_thân thành những hình_tượng khác nhau đáng chú_ý nhất phải kể đến will với hình_ảnh một chàng nhiếp_ảnh_gia điển_trai và đầy cá_tính anh có thói_quen lưu_giữ lại những hình_ảnh của người mình yêu điều đó đã khiến hình_ảnh của will trở_nên nổi_bật và ấn_tượng nhất so với các thành_viên trong mv này vì điều đó khi hai người chia_tay anh là người đau_đớn nhất khi nhớ về những kỷ_niệm chẳng thể_nào quên của hai người khi xưa rainboy_boys trong ước_mơ trong anh ước_mơ trong anh là mv thứ 2 của nhóm nhạc rainboy_boys sau mv ra_mắt đầu_tiên ấn_tượng walk_away trong mv này 7 chàng_trai_hóa_thân vào những câu_chuyện tình khá dễ_thương trong số đó chàng_trai điển_trai ryan_hải_đăng hô biến mình thành một chàng nhiếp_ảnh_gia đường_phố ghi lại những khoảnh_cách của cuộc_sống và con_người sài_gòn bên cạnh đó chàng còn ghi lại những khoảnh_khắc tình_yêu tuyệt_diệu của 6 thành_viên rainboy_boys nổi_bật và gây ấn_tượng đặc_biệt với khán_giả chính là hình_ảnh cuối_cùng của anh_chàng ira_hoàng_thy giúp người bạn gái đang ngồi trên xe_lăn đi dạo trên phố_phường đây cũng là khoảnh_khắc đầy ý_nghĩa khép lại ước_mơ trong anh v music trong xinh_tươi việt_nam là một trong những mv nổi_tiếng nhất của v music khi lê_thiên_bảo chưa tách nhóm xinh_tươi việt_nam cũng góp_phần giúp học_trò của hồ_ngọc_hà gây_dựng được hình_ảnh đẹp trong lòng công_chúng bốn chàng_trai hóa_thân thành những chàng nhiếp_ảnh_gia dễ_thương và điển_trai đi khắp miền để ghi lại những hình_ảnh đẹp về quê_hương đất_nước trong hành_trình đó các anh đã ghi lại những khoảnh_khắc khó quên về người con_gái việt_nam trong tà áo_dài một mv với những khoảnh_khắc ý_nghĩa 4 chàng nhiếp_ảnh_gia v music thực_sự đã mang đến một sản_phẩm đáng nhớ cho người xem tiêu_châu_như_quỳnh trong có bao điều hợp_tác cùng rapper antonio_maximus có bao điều là mv của tiêu_châu_như quỳnh sau khi rời khỏi giọng hát việt 2012 mv mang đến cho khán_giả những hình_ảnh về cuộc_sống thường_nhật của sài_gòn năng_động ồn_ã nhưng vẫn đầy bình_yên hóa_thân là một nữ nhiếp_ảnh_gia đường_phố cá_tính xinh_đẹp như quỳnh đã ghi lại nhiều khoảnh_khắc ấn_tượng qua thông_qua ống_kính của mình trong hành_trình rong_ruổi của mình một ngày nọ cô gặp một em bé bán hoa dạo sự trong_trẻo ngây_thơ và sự lam_lũ của cô_bé đã để lại nhiều suy_nghĩ trong nhiếp_ảnh_gia trẻ tuổi về những con_người thầm_lặng tạo nên sắc_màu rực_rỡ cho thủ_đô tươi đẹp mv chuyển_tải tới mọi người thông_điệp ý_nghĩa nếu chịu_khó quan_sát bạn sẽ thấy cuộc_sống quanh mình thật đẹp_đẽ và ấm_áp biết_bao phùng_ngọc_huy trong déjà_vu déjà_vu là mv đánh_dấu sự trở_lại của hồng_mơ giải 3 tiếng hát truyền_hình sau thời_gian ở ẩn trong mv bạn diễn của cô là nam ca_sĩ điển_trai phùng_ngọc_huy trong mv phùng_ngọc_huy vào vai anh_chàng nhiếp_ảnh đẹp_trai vô_tình thấy cô_gái bán hàng nước giỏi đàn hát đêm về anh mơ thấy cô xuất_hiện trên sân_khấu ca_nhạc với vai_trò ca_sĩ nổi_tiếng cảm_giác đó chỉ thoáng qua nhưng sau đó đã là hiện_thực khi anh_chàng vô_tình gặp lại cô theo đất_việt \n",
            "__label__nhịp_sống vợ phải quỳ gối mới được nói_chuyện cười zing vn hai bợm nhậu nói_chuyện với nhau dạo này mày đi nhậu mà không sợ vợ la_ó sao ôi trời vợ tao sợ tao lắm vậy là mày bản_lĩnh giống tao rồi mày biết không khi tao đi nhậu về vợ phải quỳ gối mới nói_chuyện được với tao thế thì mày hơn đứt tao rồi chỉ tao cách với dễ ợt khi nhậu về tao chui xuống gầm giường định_nghĩa kết_hôn với mỗi phái định_nghĩa kết_hôn lại khác nhau hoàn_toàn \n",
            "__label__công_nghệ lumia 520 sẽ có giá 3 9 triệu đồng tại việt_nam công_nghệ zing vn dự_kiến sản_phẩm sẽ được bán ra vào ngày 1 4 và việt_nam chính là thị_trường đầu_tiên nokia chọn để phát_hành chiếc điện_thoại chạy windows_phone 8 này lumia 520 sẽ có giá 3 9 triệu đồng tại việt_nam dự_kiến sản_phẩm sẽ được bán ra vào ngày 1 4 và việt_nam chính là thị_trường đầu_tiên nokia chọn để phát_hành chiếc điện_thoại chạy windows_phone 8 này lumia 520 là một trong 2 chiếc smartphone của nokia ra_mắt tại triển_lãm mwc vừa_qua sản_phẩm này được nhắm vào phân_khúc smartphone tầm thấp nhưng cấu_hình khá ấn_tượng cụ_thể lumia 520 tích_hợp màn_hình 4 inch độ_phân_giải 480x800 pixel chip lõi kép tốc_độ 1 ghz ram 512 mb và camera sau 5 megapixel không có đèn flash khi bán ra lumia 520 sẽ là điện_thoại windows_phone 8 rẻ nhất trên thị_trường đây được xem là cấu_hình mơ_ước đối_với một sản_phẩm tầm thấp đó là chưa kể đến việc nó còn được tích_hợp tính_năng cảm_ứng siêu_nhạy super_sensitive_touch cho khả_năng thao_tác cả bằng găng_tay dày bộ_nhớ_trong của máy là 8 gb máy mỏng 9 1 mm và nặng 124 gram bên cạnh đó chiếc lumia 720 cũng sẽ ra_mắt thị_trường việt trong đợt phát_hành này với giá 7 4 triệu đồng lumia 720 được đánh_giá cao tại mwc vừa_qua model này hướng đến phân_khúc smartphone tầm trung với màn_hình 4 3 inch độ_phân_giải wvga 480 x 800 pixel chip lõi kép tộc độ 1 2 ghz ram 512 mb và camera sau 6 7 megapixel camera của lumia 720 sử_dụng cùng ống_kính góc rộng carl_zeiss f 1 9 mà theo quảng_cáo của nokia là cho chất_lượng ảnh chụp ngang_ngửa với những smartphone có giá cao hơn nhiều lumia 720 sẽ có giá 7 4 triệu đồng lumia 720 được đánh_giá là chiếc smartphone đẹp nhất từ trước đến nay trong gia_đình nhà lumia với độ mỏng hợp_lý 9 mm nặng 128 gram và thiết_kế nguyên khối chắc_chắn model này cũng được tích_hợp tính_năng sạc không dây nhưng phải qua một bộ vỏ ngoài dự_kiến bộ đôi này sẽ được phát_hành ra thị_trường từ ngày 1 4 hiện_tại chuỗi cửa_hàng viettel_store đã chuẩn_bị nhận đặt trước sản_phẩm này 15 31 3 với nhiều phần quà hấp_dẫn chẳng_hạn như tặng phiếu mua hàng hoặc trúng một chiếc lumia 520 hoặc 720 miễn_phí thành_duy_theo infonet \n",
            "__label__thể_thao hà_nội t t chốt danh_sách dự afc cup thể_thao việt_nam zing vn tiền_vệ có lối chơi sáng_tạo bậc nhất của hà_nội t t benicio được hlv phan_thanh_hùng loại khỏi danh_sách dự afc cup để giành sức cho sân_chơi v league hà_nội t t chốt danh_sách dự afc cup tiền_vệ có lối chơi sáng_tạo bậc nhất của hà_nội t t benicio được hlv phan_thanh_hùng loại khỏi danh_sách dự afc cup để giành sức cho sân_chơi v league ngày hôm_qua hà_nội t t đã chính_thức chốt danh_sách cầu_thủ tham_dự sân_chơi afc_cup bất_chấp việc có lực_lượng khá mỏng ở mùa_giải năm nay hlv phan_thanh_hùng vẫn quyết_định sử_dụng những quân bài tốt nhất của mình cho sân_chơi châu_lục nội_binh có hồng_sơn hồng_minh văn_biển công_vinh ngoại_binh có cristiano gonzalo matias sự vắng_mặt đáng tiếc duy_nhất trong danh_sách dự afc_cup của hà_nội t t là tiền_vệ có lối chơi rất sáng_tạo benicio có_lẽ hlv phan_thanh_hùng quyết_định cất cầu_thủ con cưng này cho mục_tiêu bảo_vệ chức vô_địch v league theo kết_quả chia bảng afc_cup 2011 mới được lđbđ châu_á afc công_bố đương_kim vô_địch v league hà_nội t t sẽ nằm bảng g cùng clb muang_thong_united của thái_lan tampines_rovers singapore victory sc maldives đây là bảng đấu khá cân_bằng và thầy_trò hlv phan_thanh_hùng sẽ phải vất_vả tranh 2 vé đi tiếp với các đội mạnh của thái_lan và singapore dù vậy nếu chơi đúng sức hà_nội t t hoàn_toàn có khả_năng ghi tên vào vòng đấu_loại trực_tiếp giống như thành_tích mà b bình dương và shb_đà_nẵng đã làm được_mùa trước ngày 2 3 tới thầy_trò hlv phan_thanh_hùng sẽ chính_thức bước ra sân_chơi châu_lục với chuyến làm_khách của clb muang_thong_united lâm_thỏa_theo bưu_điện việt_nam \n",
            "__label__thời_sự vụ xe điên gây tai_nạn ở sài_gòn tài_xế bị tâm_thần thời_sự zing vn bị khống_chế sau khi gây tai_nạn liên_hoàn tài_xế xe bmw phun nước_bọt vung chân đạp loạn_xạ các cảnh_sát gia_đình cho_hay ông này bị bệnh_tâm_thần tâm_lý bất_ổn tối 21 11 công_an quận 3 tp hcm cho biết đã làm rõ một_số tình_tiết liên_quan đến vụ xe điên gây tai_nạn rồi tông csgt bỏ chạy tài_xế là ông phạm_cao_v ngụ quận 2 vẫn mất_tích gia_đình cùng cơ_quan_chức_năng đang truy_tìm 13h30 cùng ngày anh v lái_xe bmw màu trắng bks 63a lưu_thông trên đường điện_biên_phủ hướng từ nam_kỳ_khởi_nghĩa ra ngã tư hàng_xanh quận bình_thạnh trên đường đi tài_xế này gây tai_nạn với xe_máy do chị đỗ_thị_liên_h 29 tuổi ngụ quận tân_bình điều_khiển thấy ôtô không dừng lại mà bỏ chạy nhiều người đi đường đuổi theo tài_xế tông vào xe đặc_chủng để bỏ chạy ảnh nguyễn_thành chiếc bmw chạy đến giao_lộ điện_biên_phủ hai_bà_trưng thì bị một csgt chặn bắt tuy_nhiên tài_xế cố_tình tông vào xe đặc_chủng để thoát_thân csgt rút súng bắn chỉ_thiên cảnh_cáo do đường tắc nên tài_xế phải tấp vào lề_đường hai_bà_trưng nhưng lại chốt cửa cố_thủ trong xe hơn 30 phút sau trung_tá lê_văn_thanh tổ_trưởng điều_tra xử_lý tai_nạn đội csgt công_an quận 3 đến thuyết_phục ông v mới chịu mở_cửa tuy_nhiên anh ta phun nước_miếng vào anh_em vung chân đạp loạn_xạ và cào_cấu tôi ông thanh nói một_số người đi đường bức_xúc xông vào đánh tài_xế nhưng được csgt can_ngăn một lúc sau người_nhà xuất_hiện ông v mới dần bình_tâm rồi bỏ đi clip csgt khống_chế tài_xế ôtô điên tài_xế ôtô tông một cô_gái đi xe_máy rồi bỏ chạy khi bị cảnh_sát giao_thông yêu_cầu dừng thì nghi_can tông vào lực_lượng chức_năng cố_thủ trong xe sau đó gia_đình cung_cấp giấy_tờ xe bmw cùng giấy_tờ cá_nhân liên_quan đến ông v theo đó ôtô đứng_tên một công_ty ở tiền_giang nơi mẹ ông v làm_việc ông v có bệnh_án bệnh nan_y và được bệnh_viện xác_nhận bị tâm_thần trước khi bị bệnh người đàn_ông này có giấy_phép lái ôtô theo gia_đình ông v sau khi bị bệnh nan_y do dùng nhiều thuốc để điều_trị nên người này có dấu_hiệu tâm_thần tâm_lý bất_ổn gần đây ông ta liên_tục đòi lấy ôtô đi chơi gia_đình không cho thì đòi tuyệt_thực từ mặt mẹ và vợ_con trưa 21 11 thấy mọi người đi vắng ông v lấy ôtô đi lòng_vòng và gây ra vụ_việc lái_xe bmw tông cảnh_sát giao_thông ở sài_gòn tài_xế xe bmw tông một cô_gái đi xe_máy rồi bỏ chạy khi bị lực_lượng chức_năng yêu_cầu dừng tài_xế này tông xe vào cảnh_sát giao_thông và xe đặc_chủng sau đó cố_thủ bên trong \n",
            "__label__thế_giới lính nga nhảy_dù xuống tảng băng trôi trên bắc_cực thế_giới zing vn 50 binh_sĩ nga vừa đồng_loạt nhảy khỏi máy_bay ilyushin 76 xuống một tảng băng trôi gần bắc_cực trong cuộc tập_trận tìm_kiếm cứu nạn nguy_hiểm đại_tá yevgeny_meshkov phát_ngôn_viên lực_lượng lính_dù cho biết dù thời_tiết giá_lạnh kèm theo gió lớn nhưng các binh_sĩ vẫn thực_hiện tốt nhiệm_vụ tiếp đất và nhận hàng_hóa họ sử_dụng hệ_thống dù arbalet cho_phép nhảy ra từ máy_bay đang di_chuyển với vận_tốc 400 km h binh_sĩ nhảy_dù khỏi máy_bay ilyushin 76 ảnh itar tass theo quân_đội nga cuộc tập_trận này nhằm mục_đích tăng_cường khả_năng tìm_kiếm cứu nạn để ứng_phó kịp_thời với những tình_huống khẩn_cấp ở bắc_cực những người tham_gia tập_trận phải dựng trại trong điều_kiện khắc_nghiệt dao và súng_trường giúp họ chống lại các loài động_vật hoang_dã ngoài những con gấu_bắc_cực đói ăn sự va_chạm của các tảng băng trôi hay bề_mặt băng sụt lún có_thể khiến họ phải trả_giá bằng mạng sống cờ crimea tung bay ảnh rt những binh_sĩ tham_gia huấn_luyện sẽ cắm cờ crimea ở khu_vực đích_thân thủ_tướng crimea ông sergey_aksyonov trao lá cờ này cho các binh_sĩ bán bán_đảo crimea cũng là nơi đặt trụ_sở của hạm_đội biển_đen của nga \n",
            "__label__thời_trang ngắm vĩnh_thụy đầy chất chơi thời_trang zing vn những khoảnh_khắc ngẫu_hứng chụp tình_cờ vĩnh_thụy tại một nơi công_cộng đã vẽ nên một giải bạc siêu_mẫu mạnh_mẽ nam_tính và đầy chất chơi ngắm vĩnh_thụy đầy chất chơi những khoảnh_khắc ngẫu_hứng chụp tình_cờ vĩnh_thụy tại một nơi công_cộng đã vẽ nên một giải bạc siêu_mẫu mạnh_mẽ nam_tính và đầy chất chơi sau hơn hai tháng ròng_rã cùng đoàn phim và gần một tháng quay ngoại_cảnh ở đà_lạt vai diễn của vĩnh_thụy trong bộ phim nhật_ký bạch_tuyết đã kết_thúc hiện_tại vĩnh_thụy đang dành thời_gian nghỉ_ngơi để chuẩn_bị bước vào giai_đoạn tập_luyện cao_độ cho cuộc thi mister_international 2009 mà vĩnh_thụy sẽ là người_mẫu đại_diện việt_nam tham_dự mister_international là cuộc_thi mà tiến_đoàn đã từng đăng_quang năm 2008 năm nay cuộc thi sẽ diễn ra vào tháng 11 tại đài_loan chia_sẻ thêm những kế_hoạch sắp tới vĩnh_thụy tâm_sự hiện_tại có vài bộ phim đang mời thụy tham_gia nhưng thụy đang cân_nhắc về mặt thời_gian để đảm_bảo việc tập_luyện cho cuộc_thi mister_international sắp tới với cuộc_thi này thụy mong mình sẽ có cơ_hội tự trao dồi thêm kiến_thức về nghề cũng như có thêm dịp bước ra ngoài cọ_xát và hội_nhập cùng người_mẫu các nước khác mời bạn cùng ngắm bộ ảnh mới_mẻ của vĩnh_thụy theo dân_trí \n",
            "__label__du_lịch bố_mẹ dừng tàu lượn siêu_tốc vì lo cho con_gái du_lịch zing vn quá giận vì con chơi trò mạo_hiểm mà không được phép hai vị phụ_huynh đã cho dừng cả đoàn tàu lượn siêu_tốc trong một công_viên giải_trí ở trung_quốc theo scmp sự_việc diễn ra ở công_viên giải_trí queershan tại liễu_châu khu_tự_trị dân_tộc choang_quảng_tây hôm 6 2 một thiếu_nữ 14 tuổi rất muốn được đi tàu lượn siêu_tốc nhưng bố_mẹ không đồng_ý trong lúc họ sơ_ý em đã lẻn vào ngồi trên xe lo_lắng tức_giận vì hành_động của con_gái bố_mẹ em đã vào trung_tâm điều_khiển trò_chơi và yêu_cầu dừng tàu lượn lại ngay_lập_tức để họ đưa con_gái ra khỏi đoàn tàu nhân_viên khu giải_trí phải trèo lên đường_ray để đưa cô_gái xuống ảnh scmp đoàn tàu lượn dừng lại khi đã lăn bánh được một đoạn ngắn sự_việc bất_ngờ khiến các hành_khách tưởng có sự_cố về kỹ_thuật nhưng nhân_viên khu giải_trí giải_thích rằng chuyến đi bị ngừng lại do phụ_huynh không đồng_ý cho con_gái tham_gia sau sự_việc nhiều người lên_tiếng chỉ_trích cho_rằng ông bố bà mẹ hành_động thái quá tuy_vậy cũng có người tỏ ra thông_cảm trước sự lo_lắng của cặp vợ_chồng này đặc_biệt sau vụ tai_nạn về một thiếu_nữ 14 tuổi văng khỏi đu_quay và thiệt_mạng xảy ra hôm 3 2 ở công_viên zhaohua trùng_khánh trung_quốc \n",
            "__label__thời_sự cụ bà 84 tuổi đặc_trị bệnh chó dại thời_sự zing vn người bị chó dại cắn chưa phát bệnh thì chỉ cần liều duy_nhất kèm theo hướng_dẫn của bà cụ phạm_thị_trinh 84 tuổi là có_thể khỏi bệnh liều thuốc đặc_trị bệnh chó dại cắn nhiều năm trở_lại đây người_dân vùng núi nam_dương bắc_giang vẫn thường rỉ_tai nhau về cách điều_trị bệnh chó dại cắn độc_đáo bằng thuốc_nam của cụ bà phạm_thị_trinh sn 1931 ở thôn biềng xã nam_dương dù năm nay đã bước qua cái tuổi xưa_nay hiếm nhưng đôi mắt cụ vẫn rất tinh hàm_răng hạt bắp đen_láy không giống hình_ảnh chống gậy lưng còng như các cụ cùng độ tuổi khác tự tay pha ấm trà vùng nam_dương mời khách cụ trinh vừa kể về cơ_duyên với phương_thuốc đặc_biệt này cụ bảo mình sinh ra và lớn lên ở quỳnh_thái quỳnh_phụ thái_bình vào những năm 30 thế_kỷ trước trong một gia_đình đông anh_em gia_đình có truyền_thống bốc thuốc chữa bệnh từ nhiều đời trong nhà có rất nhiều các loại thuốc khác nhau hàng ngày có nhiều người tới khám bệnh trước đây các anh_chị tôi đi làm_ăn và lập gia_đình sớm chỉ còn tôi ở nhà hầu đèn nước cho thầy chữa bệnh thỉnh_thoảng hết thuốc thầy lại đeo bị dẫn tôi đi hái thuốc về sao thầy tôi có kể lại nghề bốc thuốc chữa bệnh được cụ nội truyền lại năm 9 tuổi tôi cũng có xin thầy được học bốc thuốc chữa bệnh nhưng thầy mắng con_gái học làm gì cụ kể thời đó cứ vào mùa hè nắng_nóng là bệnh chó dại lại tăng đột_biến trong vùng lại không ai chữa được bệnh nên hầu_như ngày nào cũng có người tới xin thuốc bà thường được bố cho l đi chế_biến thuốc theo hướng_dẫn do phương_thuốc đơn_giản nên bà còn nhớ rõ bà cụ phạm_thị_trinh 84 tuổi với phương_thuốc đặc_trị bệnh dại do chó cắn đến năm 14 tuổi chiến_tranh khiến cả gia_đình bà trinh phải sơ_tán lên vùng nam_dương huyện lục_nam để sinh_sống và nhanh_chóng hòa_nhập với môi_trường ở đây bằng nghề buôn các mặt_hàng nông_sản vào mùa nắng_nóng nhiều người_dân ở trong vùng bị chó dại cắn chứng_kiến cảnh người dân_nghèo không có tiền điều_trị nên phát dại không kiểm_soát được hành_vi và gây nguy_hại cho những người xung_quanh bà trinh bắt_đầu điều_chế liều thuốc chữa_trị mà từng phụ thầy chữa bệnh trước đó những viên thuốc đặc_trị virus dại do chó cắn được điều_chế vê thành từng viên màu đen như hạt nhãn liều thuốc được lấy từ những nguyên_liệu rất đơn_giản và gần_gũi gồm nhọ_nồi nọc_độc con cành cành gạo_nếp cơm nhão trong đó quan_trọng nhất là nọc_độc của con cành cành hay còn gọi là con văn_liệu có đầu màu đỏ thường thấy ở ruộng rau_muống khi bắt được con cành cành chỉ cần lấy phần nọc_độc ở đuôi đem phơi khô và tán nhuyễn thành bột gạo_nếp được sao vàng và tán nhuyễn nhọ_nồi chỉ được lấy từ chảo nấu bếp củi không được lấy từ các nồi khác ba nguyên_liệu trên cùng với cơm nhão kết_hợp theo tỉ_lệ 1 1 1 1 sau đó dùng tay vê thành từng viên bằng đầu đũa rồi đem phơi khô là dùng được viên thuốc khi điều_chế xong sẽ có màu xám đen giống như hạt nhãn cứu người bị chó dại cắn cầm lọ thuốc trên tay cụ trinh cho_biết mỗi lần chế thuốc đều làm sẵn một lọ dự_phòng loại thuốc này không mùi không vị khi uống vào sẽ có cảm_giác say người nôn_nao rất mệt_mỏi tùy vào thể_trạng của mỗi người sẽ sử_dụng liều_lượng phù_hợp người bình_thường sẽ được dùng một liều 6 7 viên cùng một lúc nếu ai có_thể trạng béo tốt sẽ dùng tới 10 viên hay người thể_trạng yếu hơn sẽ chỉ dùng 4 5 viên sau bữa cơm thuốc sẽ cho tác_dụng về cảm_giác khắp cơ_thể chỉ sau vài phút uống người mệt_mỏi nôn_nao khó_chịu sau khi sử_dụng liều thuốc cần phải kiêng_kỵ nhạc đám_ma hai ba tháng ngoài_ra người_bệnh cũng cần phải ăn_uống điều_độ bồi_bổ sức_khỏe mới nhanh hồi lại sức với loại thuốc này người bình_thường uống vào cũng sẽ có cảm_giác mệt_mỏi như người_bệnh tuy_nhiên nếu không thực_sự bị chó dại cắn thì không nên dùng thuốc bởi nó sẽ gây tình_trạng mệt_mỏi nhiều ngày cụ trinh chia_sẻ nghe thì phương_thuốc khá đơn_giản với những nguyên_liệu sẵn có nhưng khi bắt_tay vào làm không hề như_vậy vì trong thành_phần có nọc_độc của côn_trùng nếu làm không đúng tỉ_lệ và quy_trình thì sẽ phản_tác_dụng anh nguyễn_thọ_ngát phải ảnh con_trai út cụ trinh kể về những kỷ_niệm người_bệnh tới điều_trị tại nhà nhắc tới những bệnh_nhân mình từng chữa_trị bà trinh cho_hay cách đây vài năm có một người đàn_ông ở cùng xã nhưng khác thôn bị chó dại cắn sau nhiều ngày mới đến xin thuốc lúc đó số thuốc dự_phòng không đủ liều chữa_trị mà vào mùa khô nguyên_liệu gần_như không có tôi khuyên người_nhà đưa đi bệnh_viện tiêm vắc xin cho kịp tuy_nhiên gia_đình khó_khăn và biết tôi từng điều_trị cứu nhiều người nên đã xin được tôi chữa_trị lúc đó thấy hoàn_cảnh bệnh_nhân khó_khăn tôi đi khắp các ruộng rau nhưng cũng chỉ bắt được vài con cành cành về sao cùng các nguyên_liệu khác làm thuốc may_mắn là cộng với số thuốc còn lại trong lọ vừa đủ một liều điều_trị phải mất hai ngày sau người_bệnh đó mới được uống thuốc và không có biểu_hiện gì lạ anh nguyễn_thọ_ngát 42 tuổi con_trai út cụ trinh chia_sẻ thuốc của mẹ tôi chỉ có tác_dụng với những người mới bị chó dại cắn nghĩa_là chưa phát dại người nào có biểu_hiện xùi bọt mép không điều_khiển được hành_vi bản_thân nữa thì thuốc vô tác_dụng tính ra cũng hàng ngàn viên thuốc được điều_chế và chữa cho hàng trăm người trong vùng mẹ tôi cũng từng thử thuốc cho một con chó mới bị cắn bởi con chó dại khác kết_quả con chó được cứu sống và khỏe_mạnh còn ông nguyễn_văn_kính chủ_tịch ubnd xã nam_dương cho biết bà_phạm_thị_trinh đã sống ở đây nhiều năm và được người_dân trong vùng biết đến với phương_thuốc đặc_trị virus dại rất nhiều người không_chỉ trong xã mà các vùng lân_cận cũng tới xin được điều_trị bà trinh thường cho thuốc miễn_phí và chữa khỏi hoàn_toàn cho họ \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ1aBV9Aysr0",
        "outputId": "3477b33e-8b6d-4d68-eb5c-8c22666b60fa"
      },
      "source": [
        "# Thống kê số lượng data theo nhãn\r\n",
        "count = {}\r\n",
        "for line in open('news_categories.txt'):\r\n",
        "    key = line.split()[0]\r\n",
        "    count[key] = count.get(key, 0) + 1\r\n",
        "\r\n",
        "for key in count:\r\n",
        "    print(key, count[key])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__label__thể_thao 2611\n",
            "__label__âm_nhạc 2595\n",
            "__label__nhịp_sống 2613\n",
            "__label__công_nghệ 2595\n",
            "__label__thời_sự 2607\n",
            "__label__thế_giới 2602\n",
            "__label__thời_trang 2596\n",
            "__label__du_lịch 2593\n",
            "__label__sống_trẻ 2602\n",
            "__label__giáo_dục 2603\n",
            "__label__kinh_doanh 2597\n",
            "__label__pháp_luật 2592\n",
            "__label__giải_trí 2604\n",
            "__label__phim_ảnh 2596\n",
            "__label__xe_360 2602\n",
            "__label__ẩm_thực 2482\n",
            "__label__xuất_bản 2599\n",
            "__label__sức_khỏe 2589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyP5ZyaZysua",
        "outputId": "9862f001-eeca-486d-d4a0-4ab4c62f6e8d"
      },
      "source": [
        "# Thống kê các word xuất hiện ở tất cả các nhãn\r\n",
        "total_label = 18\r\n",
        "vocab = {}\r\n",
        "label_vocab = {}\r\n",
        "for line in open('news_categories.txt'):\r\n",
        "    words = line.split()\r\n",
        "    # lưu ý từ đầu tiên là nhãn\r\n",
        "    label = words[0]\r\n",
        "    if label not in label_vocab:\r\n",
        "        label_vocab[label] = {}\r\n",
        "    for word in words[1:]:\r\n",
        "        label_vocab[label][word] = label_vocab[label].get(word, 0) + 1\r\n",
        "        if word not in vocab:\r\n",
        "            vocab[word] = set()\r\n",
        "        vocab[word].add(label)\r\n",
        "\r\n",
        "count = {}\r\n",
        "for word in vocab:\r\n",
        "    if len(vocab[word]) == total_label:\r\n",
        "        count[word] = min([label_vocab[x][word] for x in label_vocab])\r\n",
        "        \r\n",
        "sorted_count = sorted(count, key=count.get, reverse=True)\r\n",
        "for word in sorted_count[:100]:\r\n",
        "    print(word, count[word])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "và 14255\n",
            "của 13177\n",
            "là 9983\n",
            "có 9162\n",
            "được 9131\n",
            "trong 8654\n",
            "một 7575\n",
            "cho 7483\n",
            "với 7195\n",
            "không 6591\n",
            "các 6300\n",
            "người 6088\n",
            "khi 6011\n",
            "này 5301\n",
            "đến 5165\n",
            "để 5123\n",
            "đã 4431\n",
            "nhiều 4167\n",
            "trên 3842\n",
            "từ 3820\n",
            "vào 3617\n",
            "đó 3207\n",
            "những 3097\n",
            "ở 2943\n",
            "ra 2767\n",
            "tại 2756\n",
            "vn 2738\n",
            "lại 2673\n",
            "cũng 2622\n",
            "phải 2615\n",
            "còn 2589\n",
            "theo 2565\n",
            "nhưng 2545\n",
            "zing 2519\n",
            "về 2170\n",
            "sau 2047\n",
            "làm 1983\n",
            "lên 1921\n",
            "hơn 1755\n",
            "đây 1692\n",
            "năm 1654\n",
            "sẽ 1597\n",
            "chỉ 1569\n",
            "cả 1534\n",
            "cùng 1490\n",
            "ngày 1484\n",
            "như 1467\n",
            "mà 1458\n",
            "vẫn 1386\n",
            "đi 1373\n",
            "2 1358\n",
            "mới 1357\n",
            "khác 1300\n",
            "3 1296\n",
            "hai 1278\n",
            "qua 1250\n",
            "bạn 1138\n",
            "bên 1137\n",
            "1 1136\n",
            "khiến 1122\n",
            "5 1114\n",
            "lần 1051\n",
            "mình 1045\n",
            "lớn 1030\n",
            "bị 1022\n",
            "biết 1013\n",
            "trước 1000\n",
            "rất 991\n",
            "tới 968\n",
            "bằng 948\n",
            "mang 929\n",
            "nên 897\n",
            "4 896\n",
            "đang 870\n",
            "nước 863\n",
            "cách 863\n",
            "việt_nam 861\n",
            "đầu 849\n",
            "10 847\n",
            "việc 840\n",
            "nếu 835\n",
            "vừa 826\n",
            "thấy 824\n",
            "hàng 807\n",
            "vì 806\n",
            "ảnh 799\n",
            "đều 796\n",
            "nhau 788\n",
            "thời_gian 787\n",
            "sự 764\n",
            "anh 760\n",
            "6 737\n",
            "nhất 733\n",
            "ngoài 720\n",
            "điều 712\n",
            "hay 706\n",
            "giữa 699\n",
            "số 699\n",
            "từng 697\n",
            "thêm 692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV6dRNX6ysxW"
      },
      "source": [
        "# loại stopword khỏi dữ liệu\r\n",
        "# lưu file dùng về sau\r\n",
        "stopword = set()\r\n",
        "with open('stopwords.txt', 'w') as fp:\r\n",
        "    for word in sorted_count[:100]:\r\n",
        "        stopword.add(word)\r\n",
        "        fp.write(word + '\\n')\r\n",
        "    \r\n",
        "def remove_stopwords(line):\r\n",
        "    words = []\r\n",
        "    for word in line.strip().split():\r\n",
        "        if word not in stopword:\r\n",
        "            words.append(word)\r\n",
        "    return ' '.join(words)\r\n",
        "    \r\n",
        "    \r\n",
        "with open('news_categories.prep', 'w') as fp:\r\n",
        "    for line in open('news_categories.txt'):\r\n",
        "        line = remove_stopwords(line)\r\n",
        "        fp.write(line + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MwgE0hDys4j",
        "outputId": "edb10452-2079-4a31-b202-200a626bc8b5"
      },
      "source": [
        "!head news_categories.prep"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "head: cannot open 'news_categories.prep' for reading: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3ljF5EizLJr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DmhHkG7zLMj",
        "outputId": "9f29a18f-eeac-4138-f03b-104ba109e84a"
      },
      "source": [
        "# Chia tập train/test\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "test_percent = 0.2\r\n",
        "\r\n",
        "text = []\r\n",
        "label = []\r\n",
        "\r\n",
        "for line in open('news_categories.prep'):\r\n",
        "    words = line.strip().split()\r\n",
        "    label.append(words[0])\r\n",
        "    text.append(' '.join(words[1:]))\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(text, label, test_size=test_percent, random_state=42)\r\n",
        "# Lưu train/test data\r\n",
        "# Giữ nguyên train/test để về sau so sánh các mô hình cho công bằng\r\n",
        "with open('train.txt', 'w') as fp:\r\n",
        "    for x, y in zip(X_train, y_train):\r\n",
        "        fp.write('{} {}\\n'.format(y, x))\r\n",
        "\r\n",
        "with open('test.txt', 'w') as fp:\r\n",
        "    for x, y in zip(X_test, y_test):\r\n",
        "        fp.write('{} {}\\n'.format(y, x))\r\n",
        "\r\n",
        "# encode label\r\n",
        "label_encoder = LabelEncoder()\r\n",
        "label_encoder.fit(y_train)\r\n",
        "print(list(label_encoder.classes_), '\\n')\r\n",
        "y_train = label_encoder.transform(y_train)\r\n",
        "y_test = label_encoder.transform(y_test)\r\n",
        "\r\n",
        "print(X_train[0], y_train[0], '\\n')\r\n",
        "print(X_test[0], y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['__label__công_nghệ', '__label__du_lịch', '__label__giáo_dục', '__label__giải_trí', '__label__kinh_doanh', '__label__nhịp_sống', '__label__phim_ảnh', '__label__pháp_luật', '__label__sống_trẻ', '__label__sức_khỏe', '__label__thế_giới', '__label__thể_thao', '__label__thời_sự', '__label__thời_trang', '__label__xe_360', '__label__xuất_bản', '__label__âm_nhạc', '__label__ẩm_thực'] \n",
            "\n",
            "long_nhật chê chuyện phương_thanh cứu siu_black sao_việt cái nhìn ngược hoàn_toàn đông long_nhật rằng phương_thanh mọi chuyện rối_tung long_nhật chê chuyện phương_thanh cứu siu_black cái nhìn ngược hoàn_toàn đông long_nhật rằng phương_thanh mọi chuyện rối_tung chuyện siu_black vỡ_nợ thực_sự tạo cơn chấn_động giới giải_trí thay_vì máu_lửa sân_khấu giọng ca núi_rừng xuất_hiện gương_mặt bơ_phờ khóe miệng nở nụ_cười gượng_gạo phương_thanh duy_nhất phát_ngôn báo_chí thừa_nhận khoản nợ tỷ đồng siu_black hoàn_toàn im_lặng thay chị trả_lời tất_cả thắc_mắc giới truyền_thông chính nữ ca_sĩ hâm_mộ gọi cái tên chanh tin phương_thanh chấp_nhận đứng_mũi_chịu_sào thân nhìn chị đầy ái_ngại khen chị tốt_tính lúc khó_khăn ai ai bè cho_rằng giọng ca mèo hoang_dại quá chuyện nhảy chịu khổ ai đuổi suy_nghĩ đông cái nhìn hoạt_động giới showbiz nam ca_sĩ long_nhật đưa nhìn_nhận hoàn_toàn khác_biệt lời nam ca_sĩ huế thân_thiết chị siu sự_cố phương_thanh rối_tung mọi thứ chuyện phương_thanh nhận quản_lý siu_black trả_lời báo_chí chứ tin nóng như_thế làm_sao tôi bỏ_qua mọi nhìn_nhận hành_động nghĩa_hiệp thật_sự tôi nực_cười muốn đứng lo chuyện nợ_nần trước_hết tiền đủ sức trả nợ người_ta thì_thôi giúp giúp đừng nửa_chừng như_vậy ý phương_thanh tiền bản_thân cô ấy thời đỉnh_cao giờ cô ấy đóng phim kiếm tiền thù_lao đóng phim thấp lắm bộ phim 40 tập đóng tháng trời nhận khoản tiền ca_sĩ hát đêm ít_ra chị ấy dám đứng chịu_trận đâu ai gan chuyện vấn_đề nợ_nần tiền_bạc tiền giúp người_ta nói cái gì bây_giờ khả_năng sao nói tôi sẵn_sàng trả giúp siu_black siu hát trả nợ tôi như_thế chứ toàn nói chung_chung trả_lời rùm_beng báo_chí gì tổ nói nói lằng_nhằng mọi thứ thôi thương_siu như_thế mười_hại siu trả nợ siu phương_thanh khẳng_định giúp siu hát kiếm tiền một_cách đấy chứ chị siu bây_giờ nói rõ_ràng chị ấy tinh_thần hát siu_hát cháy hết_mình chị ấy hát cảm_xúc giờ tâm_trạng đâu cháy nợ_nần bủa_vây như_thế hay_là muốn hát dưới người_ta đòi nợ đông khán_giả tôi chắc_chắn cần bày treo băng_rôn chủ_nợ kéo liền ý phương_án hoàn_toàn hiệu_quả phương_thanh theo_đuổi việc_làm thực_tế cô ấy muốn anh_hùng muốn ra_tay nghĩa_hiệp càng sự_việc rối giờ phương_thanh bắt_đầu cảm_thấy mệt_mỏi muốn bỏ_của_chạy_lấy_người vậy gì giúp chị siu trường_hợp tôi thân_thiết quý_mến chị siu chúng_tôi mấy chục nay thời chưa nào nổi_tiếng tôi giờ muốn giúp siu tất_cả ngồi xuống bàn_bạc kỹ chứ không_thể sồn_sồn phương_thanh bấy_lâu_nay có_thể nghệ_sĩ đứng tổ_chức đêm nhạc bán vé lấy cát xê toàn_bộ tiền thu dùng ủng_hộ chị siu cần giúp_đỡ chính chân_thành tôi tin chị siu có_thể vượt khó_khăn trí_thức trẻ 3 \n",
            "\n",
            "thư_an_nguy gửi toàn_shinoda trái_tim muốn vỡ tung sống trẻ trưa hôm_nay 24 8 an_nguy đầu_tiên viết dòng tâm_sự cảm_xúc toàn_shinoda đột_ngột 27 7 an_nguy lập_tức quay mỹ vài dự tang_lễ toàn_shinoda đột_ngột bạn_trai an_nguy hoàn_toàn suy_sụp cô chưa nào tâm_sự mất_mát thời_điểm hiện_tại gần tháng toàn_shinoda mất an_nguy bộc_bạch cảm_xúc vui buồn tức_giận đau_khổ người_thân lặng nhìn toàn_shinoda giờ hỏa_táng trưa 27 7 linh_cữu vlogger toàn_shinoda di_chuyển đài_hóa_thân hoàn_vũ_văn_điển hà_nội 16h lễ hỏa_táng kết_thúc đau_thương lời tâm_sự an_nguy đăng_tải 30 phút thu_hút 80 000 lượt like thích ủng_hộ đồng_cảm cộng_đồng mạng an_nguy viết em giận em nghĩ giận đời chẳng bao_giờ tha_thứ em giận mãi im_lặng mãi chẳng dỗ em quay nữ hèn nữ lúc_nào sợ giận sợ thương em nữa nghe em chẳng tin ngàn em chẳng_thể tin chuyện gì xảy nửa vòng trái_đất em kẻ mất chân mất tay gọi chạy nhà em ngồi cái máy_tính nực_cười em trút giận tất_cả báo tin em em gào họ chừng nào gặp tin rồi họ gặp em ngồi đọc dòng chữ màn_hình đầu_tiên em cảm_thấy bất_lực thế cứ tuột dần khỏi tay em một_cách mơ_hồ em khóc em hiểu loại động_vật máu lạnh nào em em không_thể khóc em câm_lặng thôi chia_sẻ an_nguy facebook em kẻ hèn_nhát em muốn quay em sợ sợ khóc sợ người_ta thương_hại em em không_bao_giờ muốn ai thương_hại trên_hết em sợ đối_diện sự_thật sợ nhìn nằm em sợ em gọi không_bao_giờ nghe câu trả_lời nữa em tự_nhủ giấc_mơ giấc_mơ quá dài quá thật trở_về nghĩa_là tỉnh_giấc cơn ác_mộng trở_thành hiện_thực em suy_nghĩ ác_độc em nói em bảo_vệ bất_kì kẻ nào tổn_thương lợi_dụng động em thì động anh_em yên cười kệ rồi chúng_nó hiểu thôi à chúng_nó hiểu đâu rồi chúng_nó quyết chịu hiểu đâu em kệ em muốn giết chết kẻ thêu_dệt muốn tự tay giết hết chúng_nó súng vậy nhẹ_nhàng quá dao không_chỉ nhát chục trăm hình nữa em nói rồi cần em sợ bố con thằng nào hết em sống giận_dữ em giận ông trời giận giận giận tất_cả mọi xung_quanh giận ông trời sao đem mất giận sao bỏ mọi giận sao giữ người_ta viết em giận làm_sao viết cứ quay người_ta viết nữa em giận mấy hôm dám quên tức_giận vô_lý lúc_nào em muốn đập muốn phá tức_giận ấy đè nặng em kẻ nắm lấy trái_tim em bóp nghiến lấy nó em gì em sống cuộc_sống bình_thường ăn ngủ cười nói trái_tim muốn vỡ tung đêm ngồi dưới đường nhìn ban công phòng em gọi chờ tiếng xuống đợi một_tí em đợi mãi chẳng ai xuất_hiện em nghĩ rằng cần em đợi bao_lâu thôi em đợi rồi em nhận_ra cái bao_lâu ấy không_bao_giờ nữa em tiếp_tục mất thứ tốt_đẹp xảy có_điều mất mãi_mãi em tin kiếp kiếp thật em chắc_chắn gặp tiếp_tục em thành lâm_việt_anh việt lúc_nào lặng_lẽ quan_tâm giúp_đỡ bọn em bọn em đời quên vui_vẻ đau_đớn nhắc bây_giờ em ích_kỉ đòi nữa thanh_thản vướng_bận gì đừng lo em em yếu_đuối muốn mạnh_mẽ cần đường tình dang_dở an_nguy toàn_shinoda chính_thức công_khai tình_yêu tháng an_nguy gái toàn shinoda lặng_lẽ đột_ngột bạn_trai 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r192vzlM06g_"
      },
      "source": [
        "MODEL_PATH = \"models\"\r\n",
        "\r\n",
        "import os\r\n",
        "if not os.path.exists(MODEL_PATH):\r\n",
        "    os.makedirs(MODEL_PATH)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5wx34bizQ8S",
        "outputId": "c835ab78-a686-424c-ded3-5aca549d3f0c"
      },
      "source": [
        "import os\r\n",
        "import pickle\r\n",
        "import time\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),\r\n",
        "                                             max_df=0.8,\r\n",
        "                                             max_features=None)), \r\n",
        "                     ('tfidf', TfidfTransformer()), \r\n",
        "                     ('clf', MultinomialNB())\r\n",
        "                    ])\r\n",
        "text_clf = text_clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "train_time = time.time() - start_time\r\n",
        "print('Done training Naive Bayes in', train_time, 'seconds.')\r\n",
        "\r\n",
        "# Save model\r\n",
        "pickle.dump(text_clf, open(os.path.join(MODEL_PATH, \"naive_bayes.pkl\"), 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done training Naive Bayes in 12.166719198226929 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLxhnyp70IWJ"
      },
      "source": [
        "import os\r\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2MVw9vfzQ-5",
        "outputId": "43fe6b76-fd77-4315-fdc4-7e37fb4aab19"
      },
      "source": [
        "# Xem kết quả trên từng nhãn\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "nb_model = pickle.load(open(os.path.join(MODEL_PATH,\"naive_bayes.pkl\"), 'rb'))\r\n",
        "y_pred = nb_model.predict(X_test)\r\n",
        "print(classification_report(y_test, y_pred, target_names=list(label_encoder.classes_)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            " __label__công_nghệ       0.91      0.92      0.92       532\n",
            "   __label__du_lịch       0.79      0.88      0.83       551\n",
            "  __label__giáo_dục       0.82      0.88      0.85       528\n",
            "  __label__giải_trí       0.59      0.74      0.66       487\n",
            "__label__kinh_doanh       0.78      0.84      0.81       498\n",
            " __label__nhịp_sống       0.85      0.49      0.62       497\n",
            "  __label__phim_ảnh       0.90      0.76      0.82       525\n",
            " __label__pháp_luật       0.90      0.92      0.91       543\n",
            "  __label__sống_trẻ       0.62      0.64      0.63       510\n",
            "  __label__sức_khỏe       0.79      0.88      0.83       496\n",
            "  __label__thế_giới       0.91      0.83      0.87       549\n",
            "  __label__thể_thao       0.95      0.95      0.95       508\n",
            "   __label__thời_sự       0.82      0.77      0.79       496\n",
            "__label__thời_trang       0.86      0.77      0.81       521\n",
            "    __label__xe_360       0.97      0.94      0.96       502\n",
            "  __label__xuất_bản       0.87      0.93      0.90       519\n",
            "   __label__âm_nhạc       0.83      0.87      0.85       554\n",
            "   __label__ẩm_thực       0.90      0.94      0.92       520\n",
            "\n",
            "           accuracy                           0.83      9336\n",
            "          macro avg       0.84      0.83      0.83      9336\n",
            "       weighted avg       0.84      0.83      0.83      9336\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCZweVip2xSv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heGdqZVV0GMR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GATp1orz6uB"
      },
      "source": [
        "# xem kết quả cho  văn bản model naive bayes đã load ở trên\r\n",
        "def predict(document):\r\n",
        "# document = '''Do CLB Quảng Ninh không đưa ra được kế hoạch cụ thể cho V-League 2021, HLV Phan Thanh Hùng quyết định kết thúc hợp đồng sớm một năm.\r\n",
        "\r\n",
        "# \"Tôi vừa lấy giấy thanh lý hợp đồng, chính thức chia tay Quảng Ninh\", HLV Phan Thanh Hùng nói với VnExpress sáng 15/12. \r\n",
        "# \"Tôi có tình cảm với đội bóng cũng như người hâm mộ nơi đây. Nhưng, tôi thấy mình không còn phù hợp với CLB nên nghỉ. \r\n",
        "# Trước mắt, tôi về nhà, chưa nhận lời dẫn dắt đội bóng nào'''\r\n",
        "\r\n",
        "  document = text_preprocess(document)\r\n",
        "  document = remove_stopwords(document)\r\n",
        "\r\n",
        "  label = nb_model.predict([document])\r\n",
        "  print('Predict label:', label_encoder.inverse_transform(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RlY2BBpzRCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06b0780-b797-4a0f-9b4a-5f483e6c4f65"
      },
      "source": [
        "document = '''Do CLB Quảng Ninh không đưa ra được kế hoạch cụ thể cho V-League 2021, HLV Phan Thanh Hùng quyết định kết thúc hợp đồng sớm một năm.\r\n",
        "\r\n",
        "\"Tôi vừa lấy giấy thanh lý hợp đồng, chính thức chia tay Quảng Ninh\", HLV Phan Thanh Hùng nói với VnExpress sáng 15/12. \r\n",
        "\"Tôi có tình cảm với đội bóng cũng như người hâm mộ nơi đây. Nhưng, tôi thấy mình không còn phù hợp với CLB nên nghỉ. \r\n",
        "Trước mắt, tôi về nhà, chưa nhận lời dẫn dắt đội bóng nào'''\r\n",
        "\r\n",
        "predict(document)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predict label: ['__label__thể_thao']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njh_zfj0LAOx",
        "outputId": "1ed6fdda-9d53-4e16-f933-fb7f4e6e09d4"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "    \r\n",
        "start_time = time.time()\r\n",
        "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),\r\n",
        "                                             max_df=0.8,\r\n",
        "                                             max_features=None)), \r\n",
        "                     ('tfidf', TfidfTransformer()),\r\n",
        "                     ('clf', LogisticRegression(solver='lbfgs', \r\n",
        "                                                multi_class='auto',\r\n",
        "                                                max_iter=10000))\r\n",
        "                    ])\r\n",
        "text_clf = text_clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "train_time = time.time() - start_time\r\n",
        "print('Done training Linear Classifier in', train_time, 'seconds.')\r\n",
        "\r\n",
        "# Save model\r\n",
        "pickle.dump(text_clf, open(os.path.join(MODEL_PATH, \"linear_classifier.pkl\"), 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done training Linear Classifier in 203.54201650619507 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5BwpkCJLAXV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}